{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8173fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "try:\n",
    "    os.chdir('/container/mount/point')\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: Directory '/container/mount/point' does not exist.\")\n",
    "\n",
    "from utils.preprocessing import filter_and_process_asv_table\n",
    "from utils.pair_matching import discrepancyMatrix, construct_network, process_matched_pairs, generate_simulated_outcomes  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1be4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_exposure(data, target_variable, mapping, new_col, dataset_name):\n",
    "    \"\"\"\n",
    "    Preprocesses the exposure variable in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        target_variable (str): Name of the column to map.\n",
    "        mapping (dict): Dictionary mapping original values to new values.\n",
    "        new_col (str): Name of the new column to create.\n",
    "        dataset_name (str): Name of the dataset (for logging).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new exposure column and rows with missing values dropped.\n",
    "    \"\"\"\n",
    "    print(f\"\\nRunning dataset: {dataset_name}\")\n",
    "    print(f\"Covariates data (before): {data.shape}\")\n",
    "    data.loc[:, new_col] = data[target_variable].map(mapping)\n",
    "    data = data.dropna(subset=[new_col])\n",
    "    print(f\"Covariates data (after): {data.shape}\")\n",
    "    return data\n",
    "\n",
    "def set_thresholds(df, column_thresholds):\n",
    "    \"\"\"\n",
    "    Sets matching thresholds for covariates.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        column_thresholds (dict): Dictionary of column names and their threshold values.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of thresholds aligned with DataFrame columns.\n",
    "    \"\"\"\n",
    "    thresholds = np.full(df.shape[1], np.nan)\n",
    "    for col, val in column_thresholds.items():\n",
    "        if col in df.columns:\n",
    "            thresholds[df.columns.get_loc(col)] = val\n",
    "    return thresholds\n",
    "\n",
    "def match_and_simulate(df, target_variable, target_encoding, column_thresholds, n_col, output_prefix, dataset_name):\n",
    "    \"\"\"\n",
    "    Performs matching and simulates outcomes for a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        target_variable (str): Name of the exposure variable.\n",
    "        target_encoding (dict): Mapping for exposure variable to string labels.\n",
    "        column_thresholds (dict): Dictionary of covariate thresholds.\n",
    "        n_col (int): Number of randomizations for simulation.\n",
    "        output_prefix (str): Prefix for output file paths.\n",
    "        dataset_name (str): Name of the dataset (for logging).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of matched pairs.\n",
    "    \"\"\"\n",
    "    print(f\"\\nMatching and simulating for dataset: {dataset_name}\")\n",
    "    df[\"W\"] = df[target_variable]\n",
    "    df[\"W_str\"] = df[\"W\"].map(target_encoding)\n",
    "    df[\"is_treated\"] = df[\"W\"].astype(bool)\n",
    "    df[\"pair_nb\"] = np.nan\n",
    "\n",
    "    test, control = df[df[\"W\"] == 0], df[df[\"W\"] == 1]\n",
    "    print(f\"Number of test - {len(test)}\")\n",
    "    print(f\"Number of control - {len(control)}\")\n",
    "\n",
    "    thresholds = set_thresholds(df, column_thresholds)\n",
    "    scaling = np.ones(df.shape[1], dtype=int)\n",
    "\n",
    "    treated_units = df[df[\"is_treated\"]]\n",
    "    control_units = df[~df[\"is_treated\"]]\n",
    "    print(f\"Number of treated units: {treated_units.shape[0]}\")\n",
    "    print(f\"Number of control units: {control_units.shape[0]}\")\n",
    "\n",
    "    discrepancies = discrepancyMatrix(treated_units, control_units, thresholds, scaling)\n",
    "    g, pairs_dict = construct_network(discrepancies, treated_units.shape[0], control_units.shape[0])\n",
    "    matched_df = process_matched_pairs(pairs_dict, treated_units, control_units)\n",
    "\n",
    "    print(f\"Number of pairs: {len(matched_df.W)}\")\n",
    "    print(f\"Number of test individuals: {len(matched_df[matched_df.W == 0])}\")\n",
    "    print(f\"Number of control individuals: {len(matched_df[matched_df.W == 1])}\\n\")\n",
    "\n",
    "    matched_df.to_csv(f'{output_prefix}_matched_df_{target_variable}.csv', index=True)\n",
    "    simulated_outcomes = generate_simulated_outcomes(matched_df, n_col)\n",
    "    simulated_outcomes.to_csv(f'{output_prefix}_simulated_outcomes_{target_variable}.csv', index=True)\n",
    "\n",
    "    return matched_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd529d13",
   "metadata": {},
   "source": [
    "### AGP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa893bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running dataset: AGP\n",
      "Covariates data (before): (12089, 660)\n",
      "Covariates data (after): (12089, 660)\n",
      "\n",
      "Matching and simulating for dataset: AGP\n",
      "Number of test - 234\n",
      "Number of control - 11855\n",
      "Number of treated units: 11855\n",
      "Number of control units: 234\n",
      "Number of pairs: 468\n",
      "Number of test individuals: 234\n",
      "Number of control individuals: 234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AGP parameters\n",
    "K = 1000\n",
    "agp_params = {\n",
    "    \"name\": \"AGP\",\n",
    "    \"file\": \"data/AGP/agdata_smoke.csv\",\n",
    "    \"index_col\": 0,\n",
    "    \"target_variable\": \"smoking_frequency\",\n",
    "    \"mapping\": {\"Daily\": 0, \"Never\": 1},\n",
    "    \"new_col\": \"W\",\n",
    "    \"output_prefix\": \"data/AGP\",\n",
    "    \"column_thresholds\": {\"sex\": 0, \"age_cat\": 0, \"bmi_corrected\": 4},\n",
    "    \"encoding\": {0: \"Yes\", 1: \"No\"}\n",
    "}\n",
    "\n",
    "# AGP workflow\n",
    "agp_data = pd.read_csv(agp_params[\"file\"], index_col=agp_params[\"index_col\"], low_memory=False)\n",
    "agp_data = preprocess_exposure(agp_data, agp_params[\"target_variable\"], agp_params[\"mapping\"], agp_params[\"new_col\"], agp_params[\"name\"])\n",
    "agp_data.to_csv(f\"{agp_params['output_prefix']}_preprocessed.csv\", index=True)\n",
    "\n",
    "agp_matched_df = match_and_simulate(\n",
    "    agp_data, agp_params[\"new_col\"], agp_params[\"encoding\"], agp_params[\"column_thresholds\"], K, agp_params[\"output_prefix\"], agp_params[\"name\"]\n",
    ")\n",
    "agp_matched_df.to_csv(\"data/smoking_AGP_experiment.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf780b4",
   "metadata": {},
   "source": [
    "### KORA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ee67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running dataset: KORA\n",
      "Covariates data (before): (1938, 75)\n",
      "Covariates data (after): (1084, 76)\n",
      "\n",
      "Matching and simulating for dataset: KORA\n",
      "Number of test - 237\n",
      "Number of control - 733\n",
      "Number of treated units: 733\n",
      "Number of control units: 237\n",
      "Number of pairs: 440\n",
      "Number of test individuals: 220\n",
      "Number of control individuals: 220\n",
      "\n",
      "These columns have not variance and will be dropped: Index(['33231', '50139'], dtype='object')\n",
      "Final matched metadata shape: (436, 80)\n",
      "Final ASV table shape: (1469, 436)\n",
      "Final group sizes:\n",
      "smoking_bin\n",
      "0.0    218\n",
      "1.0    218\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- PARAMETERS ---\n",
    "K = 1000\n",
    "kora_params = {\n",
    "    \"name\": \"KORA\",\n",
    "    \"file\": \"data/kora_full_preprocessed_masked.csv\",\n",
    "    \"index_col\": \"u3_16s_id\",\n",
    "    \"target_variable\": \"smoking_(cat)\",\n",
    "    \"mapping\": {1: 0, 3: 1},\n",
    "    \"new_col\": \"smoking_bin\",\n",
    "    \"output_prefix\": \"data/KORA\",\n",
    "    \"column_thresholds\": {\"sex\": 0, \"age_exm\": 0, \"bmi\": 4},\n",
    "    \"encoding\": {0: \"Yes\", 1: \"No\"}\n",
    "}\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "kora_data = pd.read_csv(kora_params[\"file\"], index_col=kora_params[\"index_col\"], low_memory=False)\n",
    "kora_data = preprocess_exposure(\n",
    "    kora_data,\n",
    "    kora_params[\"target_variable\"],\n",
    "    kora_params[\"mapping\"],\n",
    "    kora_params[\"new_col\"],\n",
    "    kora_params[\"name\"]\n",
    ")\n",
    "asv = pd.read_csv(\"data/feature_table.tsv\", index_col=0, sep='\\t')\n",
    "\n",
    "# --- OVERLAP SAMPLES BEFORE MATCHING ---\n",
    "metadata_ids = kora_data.index.astype(str)\n",
    "asv_ids = asv.columns.astype(str)\n",
    "common_ids = sorted(set(metadata_ids) & set(asv_ids))\n",
    "\n",
    "kora_data_filtered = kora_data.loc[kora_data.index.astype(str).isin(common_ids)].copy()\n",
    "asv_filtered = asv.loc[:, asv.columns.astype(str).isin(common_ids)].copy()\n",
    "\n",
    "# --- PAIR-MATCHING ON FILTERED METADATA ---\n",
    "kora_matched_df = match_and_simulate(\n",
    "    kora_data_filtered,\n",
    "    kora_params[\"new_col\"],\n",
    "    kora_params[\"encoding\"],\n",
    "    kora_params[\"column_thresholds\"],\n",
    "    K,\n",
    "    kora_params[\"output_prefix\"],\n",
    "    kora_params[\"name\"]\n",
    ")\n",
    "\n",
    "# --- FILTER ASV TABLE TO MATCHED SAMPLES ---\n",
    "matched_ids = sorted(kora_matched_df.index.astype(str))\n",
    "asv_matched = asv_filtered.loc[:, matched_ids]\n",
    "\n",
    "# --- OPTIONAL: FILTER AND PROCESS ASV TABLE ---\n",
    "asv_top99_samples, asv_samples_ids = filter_and_process_asv_table(asv_matched, freq_threshold=0.01)\n",
    "\n",
    "# --- FINAL ALIGNMENT AND BALANCING ---\n",
    "final_ids = sorted(set(kora_matched_df.index.astype(str)) & set(asv_top99_samples.columns.astype(str)))\n",
    "kora_matched_df_final = kora_matched_df.loc[kora_matched_df.index.astype(str).isin(final_ids)]\n",
    "asv_top99_samples_final = asv_top99_samples.loc[:, final_ids]\n",
    "\n",
    "# Re-balance groups to the minimum group size\n",
    "group_sizes = kora_matched_df_final[kora_params[\"new_col\"]].value_counts()\n",
    "min_group_size = group_sizes.min()\n",
    "\n",
    "group_0 = kora_matched_df_final[kora_matched_df_final[kora_params[\"new_col\"]] == 0].sample(n=min_group_size, random_state=42)\n",
    "group_1 = kora_matched_df_final[kora_matched_df_final[kora_params[\"new_col\"]] == 1].sample(n=min_group_size, random_state=42)\n",
    "kora_matched_df_final = pd.concat([group_0, group_1]).sort_index()\n",
    "\n",
    "# Final alignment\n",
    "final_ids = sorted(kora_matched_df_final.index.astype(str))\n",
    "asv_top99_samples_final = asv_top99_samples_final.loc[:, final_ids]\n",
    "\n",
    "# Final checks\n",
    "assert len(final_ids) == min_group_size * 2, \"Group sizes are not equal!\"\n",
    "assert asv_top99_samples_final.shape[1] == kora_matched_df_final.shape[0], \"Sample counts do not match!\"\n",
    "\n",
    "print(\"Final matched metadata shape:\", kora_matched_df_final.shape)\n",
    "print(\"Final ASV table shape:\", asv_top99_samples_final.shape)\n",
    "print(\"Final group sizes:\")\n",
    "print(kora_matched_df_final[kora_params[\"new_col\"]].value_counts())\n",
    "\n",
    "# Draw random outcome for smoking status\n",
    "simulated_outcomes = generate_simulated_outcomes(kora_matched_df_final, K)\n",
    "\n",
    "asv_top99_samples_final.to_csv(\"data/filtered_count_table.csv\", index=True)\n",
    "kora_matched_df_final.to_csv(\"data/smoking_KORA_experiment.csv\", index=True)\n",
    "simulated_outcomes.to_csv(\"data/simulated_KORA_outcomes.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
