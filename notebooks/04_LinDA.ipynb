{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600247a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri, FloatVector\n",
    "\n",
    "\n",
    "# Convert pandas.DataFrames to R dataframes automatically.\n",
    "pandas2ri.activate()\n",
    "\n",
    "try:\n",
    "    os.chdir('/container/mount/point')\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: Directory '/container/mount/point' does not exist.\")\n",
    "\n",
    "\n",
    "from utils.helper import r_to_pandas, check_samples_overlap, generate_taxa_dict, calculate_obs_stat_and_pvalues\n",
    "from utils.helper import perform_bh_correction_and_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94780811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_unadjusted_p_values(test_stats, obs_stat, test_type):\n",
    "    \"\"\"\n",
    "    Calculate unadjusted p-values for observed test statistics using permutation test results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stats : pd.DataFrame\n",
    "        DataFrame of test statistics from permutations (rows: taxa/features, columns: permutations).\n",
    "    obs_stat : pd.Series or pd.DataFrame\n",
    "        Observed test statistics (index: taxa/features).\n",
    "    test_type : str\n",
    "        Type of test to perform. Currently supports \"two-sided\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p_value : pd.DataFrame\n",
    "        DataFrame of unadjusted p-values (index: taxa/features, column: \"p-value\").\n",
    "    \"\"\"\n",
    "    if test_type == \"two-sided\":\n",
    "        # two-sided test with absolute value tests both directions\n",
    "        # calculate the proportion of |T_rand| >= |T_obs|\n",
    "        p_value = test_stats.abs().ge(obs_stat.abs().values, axis=\"rows\")\n",
    "        p_value.index = obs_stat.index\n",
    "        p_value = p_value.mean(axis=\"columns\").sort_values().to_frame()\n",
    "        p_value.columns = [\"p-value\"]\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35445d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_unadjusted_p_values(test_stats):\n",
    "    \"\"\"\n",
    "    Calculate the minimum unadjusted p-value for each permutation by treating each column as the observed statistic.\n",
    "\n",
    "    For each permutation (column), treats its values as the observed statistics,\n",
    "    compares against all other permutations, and computes the minimum p-value across all taxa/features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stats : pd.DataFrame\n",
    "        DataFrame of test statistics from permutations (rows: taxa/features, columns: permutations).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    min_p_values : np.ndarray\n",
    "        Array of minimum unadjusted p-values for each permutation.\n",
    "    \"\"\"\n",
    "    min_p_values = []\n",
    "\n",
    "    for i in test_stats.columns:\n",
    "        # Choose random statistic as \"observed\" statistic\n",
    "        obs_stat = test_stats.loc[:, i]\n",
    "\n",
    "        # Select random statistics except the observed one\n",
    "        t = test_stats.loc[:, test_stats.columns != i]\n",
    "\n",
    "        # Select statistics greater or equal to the observed one\n",
    "        t_comp = t.abs().ge(obs_stat.abs().values, axis=\"rows\")\n",
    "\n",
    "        # Calculate unadjusted p-values\n",
    "        t_comp = t_comp.mean(axis=\"columns\")\n",
    "\n",
    "        # Save min p-value among all species\n",
    "        min_p_values.append(min(t_comp))\n",
    "        \n",
    "    min_p_values = np.array(min_p_values)\n",
    "    \n",
    "    return min_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331ab2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjusted_p_values(min_p_values, p_value):\n",
    "    \"\"\"\n",
    "    Calculate adjusted p-values using the distribution of minimum unadjusted p-values.\n",
    "\n",
    "    For each observed p-value, computes the proportion of min_p_values less than or equal to it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    min_p_values : np.ndarray or list\n",
    "        Array or list of minimum unadjusted p-values from permutations.\n",
    "    p_value : pd.DataFrame\n",
    "        DataFrame of observed unadjusted p-values (column: 'p-value').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    adj_p_values : list\n",
    "        List of adjusted p-values for each observed statistic.\n",
    "    \"\"\"\n",
    "    adj_p_values = []\n",
    "    p = p_value.shape[0]\n",
    "\n",
    "    for i in range(p):\n",
    "        adj = np.mean(min_p_values <= p_value['p-value'][i])\n",
    "        adj_p_values.append(adj)\n",
    "    \n",
    "    return adj_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3af761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_bh_correction_and_filter(stats, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform Benjamini-Hochberg correction on p-values and filter significant features.\n",
    "\n",
    "    Parameters:\n",
    "    - taxa (DataFrame): DataFrame containing taxonomic information.\n",
    "    - stats (DataFrame): DataFrame containing statistical results with 'p_value' column.\n",
    "    - alpha (float, optional): Threshold for significance. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Subset of the input DataFrame containing features with adjusted p-values <= alpha.\n",
    "    \"\"\"\n",
    "    # Perform Benjamini-Hochberg correction\n",
    "    adjusted_pvalues = sm.stats.multipletests(stats['p_value'], method='fdr_bh')[1]\n",
    "\n",
    "    # Update the DataFrame with adjusted p-values\n",
    "    stats['adjusted_pvalue'] = adjusted_pvalues\n",
    "    stats['effect'] = np.sign(stats['obs_stat'])\n",
    "\n",
    "    # Display the result\n",
    "    da_species = stats[stats['adjusted_pvalue'] <= alpha]\n",
    "\n",
    "    return da_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80022ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils = importr('utils')\n",
    "devtools = importr('devtools')\n",
    "linda = importr(\"LinDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145c594",
   "metadata": {},
   "source": [
    "### KORA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your  matched sample dataframe and ASV table\n",
    "kora_matched_df = pd.read_csv(\"data/smoking_KORA_experiment.csv\", index_col=0)\n",
    "asv = pd.read_csv(\"data/filtered_count_table.csv\", index_col=0)\n",
    "simulated_outcomes = pd.read_csv(\"data/simulated_KORA_outcomes.csv\", index_col=0)\n",
    "taxa = pd.read_csv('data/taxonomy_clean.csv', index_col=0)\n",
    "print(f\"ASV table shape (features, samples): {asv.shape}\")\n",
    "\n",
    "# Sort ASV columns to match sample order in kora_matched_df\n",
    "sample_order = list(kora_matched_df.index.astype(str))\n",
    "ASV_table = asv.reindex(sample_order, axis=1)\n",
    "\n",
    "taxa_dict = {}\n",
    "for level in ['domain', 'phylum', 'class', 'order', 'family', 'genus', 'species']:\n",
    "    df_level = ASV_table.join(taxa[level])\n",
    "    df_level = df_level.groupby(level).sum()\n",
    "    taxa_dict[level] = df_level\n",
    "taxa_dict[\"ASVs\"] = ASV_table\n",
    "\n",
    "for level in taxa_dict.keys():\n",
    "    print(f\"{level} count table shape: {taxa_dict[level].shape}\")\n",
    "\n",
    "# Overlap 16S and IgE samples\n",
    "sample_ids = ASV_table.columns.astype(str)\n",
    "matched_samples = kora_matched_df[kora_matched_df.index.astype(str).isin(sample_ids)]\n",
    "\n",
    "# Example: create a covariate DataFrame (replace 'W' with your covariate column)\n",
    "w = pd.DataFrame(matched_samples[\"W\"].values, index=matched_samples.index, columns=[\"w\"])\n",
    "\n",
    "# Now you can run your downstream analysis, e.g. LinDA\n",
    "linda_stats = calculate_obs_stat_and_pvalues(taxa_dict, w)\n",
    "print(\"------------------------- LinDA is DONE ------------------------- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulated outcomes ---\n",
    "n_iter = 1000\n",
    "alpha = 0.05\n",
    "target_variable = \"smoking_bin\"  # Make sure this matches your context\n",
    "\n",
    "for level, data in taxa_dict.items():\n",
    "    p, N = data.shape\n",
    "    if p < 20:\n",
    "        continue\n",
    "\n",
    "    print(f\"Linda test for {level} level\")\n",
    "\n",
    "    test_stats = []\n",
    "    pvalue_list = []\n",
    "    W_frame = simulated_outcomes.iloc[:, -n_iter:]\n",
    "\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        w_tmp = W_frame.iloc[:, i].to_frame(name=\"w\")\n",
    "        w_tmp.index = w_tmp.index.astype(str)\n",
    "        w_tmp = w_tmp[w_tmp.index.isin(data.columns)]\n",
    "\n",
    "        # apply linda\n",
    "        lo_tmp = linda.linda(data, w_tmp, formula=\"~w\", alpha=alpha, prev_cut=0, lib_cut=1)\n",
    "        linda_out_tmp = r_to_pandas(lo_tmp.rx2(\"output\"))\n",
    "        out = linda_out_tmp['w']\n",
    "\n",
    "        test_stats.append(out['stat'].values)\n",
    "        pvalue_list.append(out['pvalue'].values)\n",
    "\n",
    "    # Save results\n",
    "    test_stats_df = pd.DataFrame(test_stats).T\n",
    "    test_stats_df.to_csv(f'data/linda_{level}_{n_iter}_{target_variable}.csv')\n",
    "\n",
    "    pvalue_df = pd.DataFrame(pvalue_list).T\n",
    "    pvalue_df.to_csv(f'data/linda_pvalues_{level}_{n_iter}_{target_variable}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019504de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "p_value_dict = {}\n",
    "\n",
    "for level in taxa_dict.keys():\n",
    "    file_path = f'data/linda_pvalues_{level}_{n_iter}_{target_variable}.csv'\n",
    "    output_path = f'data/KORA/adj_linda_{level}_{n_iter}_{target_variable}.csv'\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"p-value adjustment procedure for {level} level\")\n",
    "\n",
    "        obs_stat = linda_stats[level]['obs_stat']\n",
    "        test_stats = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "        # Step 1: Unadjusted p-values\n",
    "        p_value = calculate_unadjusted_p_values(test_stats, obs_stat, test_type=\"two-sided\")\n",
    "\n",
    "        # Step 2: Randomized minimum p-values\n",
    "        min_p_values = min_unadjusted_p_values(test_stats)\n",
    "\n",
    "        # Step 3: Adjusted p-values\n",
    "        p_value[\"Lee et al.\"] = adjusted_p_values(min_p_values, p_value)\n",
    "\n",
    "        p_value_dict[level] = p_value\n",
    "\n",
    "        p_value.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_results_clusters = dict()\n",
    "FDR_rate = 0.2\n",
    "\n",
    "# Perform BH correction and filter results\n",
    "result = perform_bh_correction_and_filter(linda_stats['ASV'], alpha=FDR_rate)\n",
    "\n",
    "# Merge with taxonomy to include names\n",
    "result_with_taxa = result.merge(taxa, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Create a short taxon name for plotting\n",
    "result_with_taxa['short_name'] = (\n",
    "    result_with_taxa['family'].fillna('') + ' ' +\n",
    "    result_with_taxa['genus'].fillna('') + ' ' +\n",
    "    result_with_taxa['species'].fillna('')\n",
    ").str.strip()\n",
    "\n",
    "# Sort by adjusted p-value\n",
    "result_with_taxa_sorted = result_with_taxa.sort_values('adjusted_pvalue')\n",
    "\n",
    "# Bar plot for adjusted p-values\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(result_with_taxa_sorted['short_name'], result_with_taxa_sorted['adjusted_pvalue'], color='skyblue')\n",
    "plt.xlabel('Adjusted p-value')\n",
    "plt.ylabel('Family Genus Species')\n",
    "plt.title('Adjusted p-values for Differentially Abundant Species')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
